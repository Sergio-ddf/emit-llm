{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6a650532",
      "metadata": {
        "id": "6a650532"
      },
      "source": [
        "# EMit Emotion Detection Task"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# monta la repo con PAT nascosto nei Secrets\n",
        "from google.colab import userdata\n",
        "import os, wandb\n",
        "\n",
        "os.environ[\"WANDB_API_KEY\"] = userdata.get('WANDB_KEY')\n",
        "wandb.login()\n",
        "\n"
      ],
      "metadata": {
        "id": "2JIsZjXzOitS"
      },
      "id": "2JIsZjXzOitS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installazione delle dipendenze (esegui solo la prima volta)\n",
        "!pip install -q datasets emoji iterative-stratification evaluate tokenizers\n"
      ],
      "metadata": {
        "id": "5xpwet2RKElx"
      },
      "id": "5xpwet2RKElx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import principali e informazioni sull'ambiente\n",
        "import os, platform, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
        "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
        "                          TrainingArguments, Trainer)\n",
        "import datasets, emoji, evaluate, tokenizers, transformers\n",
        "\n",
        "print(f\"Python     : {platform.python_version()}\")\n",
        "print(f\"PyTorch    : {torch.__version__} (CUDA disponibile: {torch.cuda.is_available()})\")\n",
        "print(f\"Transformers: {transformers.__version__}\")\n",
        "print(f\"Datasets   : {datasets.__version__}\")"
      ],
      "metadata": {
        "id": "_FnIn-WBKIMs"
      },
      "id": "_FnIn-WBKIMs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Caricamento dei file CSV\n",
        "DATA_DIR = \"\"  # <--- modifica se i file sono in un'altra cartella\n",
        "\n",
        "train_a = pd.read_csv(os.path.join(DATA_DIR, \"emit_train_A.csv\"))\n",
        "train_b = pd.read_csv(os.path.join(DATA_DIR, \"emit_train_B.csv\"))\n",
        "\n",
        "test_in  = pd.read_csv(os.path.join(DATA_DIR, \"emit_test.csv\"))\n",
        "\n",
        "display(train_a.head())"
      ],
      "metadata": {
        "id": "eqzGr6r_KXlx"
      },
      "id": "eqzGr6r_KXlx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistiche delle etichette (frequenza nel train set)\n",
        "LABELS = ['Anger','Anticipation','Disgust','Fear','Joy','Love','Neutral','Sadness','Surprise','Trust']\n",
        "\n",
        "stats = train_a[LABELS].sum().sort_values(ascending=False)\n",
        "ax = stats.plot(kind='bar', title='Distribuzione etichette')\n",
        "ax.set_ylabel('Numero di esempi positivi')\n",
        "print(stats)"
      ],
      "metadata": {
        "id": "IUA5jIxRKgy5"
      },
      "id": "IUA5jIxRKgy5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre‑processing del testo: link, mention, hashtag, emoji\n",
        "URL_TOKEN     = \"<URL>\"\n",
        "USER_TOKEN    = \"<USER>\"\n",
        "HASHTAG_TOKEN = \"<HASHTAG>\"\n",
        "\n",
        "\n",
        "def clean(text: str) -> str:\n",
        "    \"\"\"Semplice pulizia del testo e sostituzione di token speciali.\"\"\"\n",
        "    text = re.sub(r'https?://\\S+', URL_TOKEN, text)       # link\n",
        "    text = re.sub(r'@\\w+', USER_TOKEN, text)               # mention\n",
        "    text = re.sub(r'#(\\w+)', HASHTAG_TOKEN + r' \\1', text) # hashtag → token + parola\n",
        "    text = emoji.demojize(text, language='it')               # emoji → testo\n",
        "    return text.strip()\n",
        "\n",
        "train_a['text_clean'] = train_a['text'].apply(clean)\n",
        "train_a[['text', 'text_clean']].head()"
      ],
      "metadata": {
        "id": "30QwIKOqKlyI"
      },
      "id": "30QwIKOqKlyI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split 90/10 stratificato con MultilabelStratifiedShuffleSplit\n",
        "X = train_a['text_clean'].values\n",
        "Y = train_a[LABELS].values\n",
        "\n",
        "msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.10, random_state=42)\n",
        "train_idx, val_idx = next(msss.split(X, Y))\n",
        "\n",
        "train_df = train_a.iloc[train_idx].reset_index(drop=True)\n",
        "val_df   = train_a.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "print(f\"Dimensione train: {train_df.shape[0]} – validation: {val_df.shape[0]}\")"
      ],
      "metadata": {
        "id": "4VWhO6jhKqmw"
      },
      "id": "4VWhO6jhKqmw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline: TF‑IDF uni/bi‑gram + Logistic Regression (One‑vs‑Rest)\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5_000)\n",
        "\n",
        "X_train = vectorizer.fit_transform(train_df['text_clean'])\n",
        "X_val   = vectorizer.transform(val_df['text_clean'])\n",
        "\n",
        "y_train = train_df[LABELS].values\n",
        "y_val   = val_df[LABELS].values\n",
        "\n",
        "clf = OneVsRestClassifier(LogisticRegression(max_iter=1_000, random_state=42))\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred   = clf.predict(X_val)\n",
        "macro_f1 = f1_score(y_val, y_pred, average='macro')\n",
        "print(f\"Baseline TF‑IDF + LR macro‑F1: {macro_f1:.4f}\")\n",
        "\n",
        "print(classification_report(y_val, y_pred, target_names=LABELS, zero_division=0))"
      ],
      "metadata": {
        "id": "jZhqIbNnKuzQ"
      },
      "id": "jZhqIbNnKuzQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparazione dati per il fine‑tuning di UmBERTo\n",
        "MODEL_NAME = 'Musixmatch/umberto-commoncrawl-cased-v1'  # puoi cambiarlo\n",
        "DEVICE      = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "NUM_LABELS  = len(LABELS)\n",
        "\n",
        "# Calcolo dei pesi di classe per BCE ponderata\n",
        "freqs        = train_df[LABELS].mean().values  # frequenza positivi per classe\n",
        "pos_weights  = torch.tensor((1 - freqs) / freqs, device=DEVICE)\n",
        "\n",
        "# Aggiungo colonna \"labels\" con vettore di float\n",
        "for df in (train_df, val_df):\n",
        "    df['labels'] = df[LABELS].astype(float).values.tolist()\n",
        "\n",
        "# Tokenizzazione\n",
        "MAX_LEN   = 128\n",
        "TOKENIZER = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "def tokenize_fn(batch):\n",
        "    enc = TOKENIZER(batch['text_clean'], padding='max_length', truncation=True, max_length=MAX_LEN)\n",
        "    enc['labels'] = batch['labels']\n",
        "    return enc\n",
        "\n",
        "# Conversione in HuggingFace Dataset e formattazione \"torch\"\n",
        "drop_cols = ['text', 'text_clean'] + LABELS\n",
        "\n",
        "dtrain = datasets.Dataset.from_pandas(train_df).map(tokenize_fn, batched=True, remove_columns=drop_cols)\n",
        "dval   = datasets.Dataset.from_pandas(val_df).map(tokenize_fn,   batched=True, remove_columns=drop_cols)\n",
        "\n",
        "dtrain.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "dval.set_format('torch',   columns=['input_ids', 'attention_mask', 'labels'])\n",
        "\n",
        "# Modello\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=NUM_LABELS,\n",
        "    problem_type='multi_label_classification'\n",
        ").to(DEVICE)\n",
        "\n",
        "# Mappatura etichette → id\n",
        "model.config.label2id = {lbl: i for i, lbl in enumerate(LABELS)}\n",
        "model.config.id2label = {i: lbl for i, lbl in enumerate(LABELS)}\n",
        "\n",
        "# Funzione metriche (macro‑F1)\n",
        "from torch.nn.functional import sigmoid\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    probs  = sigmoid(torch.tensor(logits))\n",
        "    preds  = (probs >= 0.5).int().numpy()\n",
        "    labels = labels.astype(int)\n",
        "    return {\"eval_macro_f1\": float(f1_score(labels, preds, average='macro', zero_division=0))}\n",
        "\n",
        "# Trainer personalizzato con BCE ponderata\n",
        "class WeightedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        # opzionale: dreniamo num_items_in_batch se presente\n",
        "        inputs.pop(\"num_items_in_batch\", None)\n",
        "\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits  = outputs.logits\n",
        "        loss    = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weights)(\n",
        "            logits, labels.float()\n",
        "        )\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "\n",
        "# Argomenti di training\n",
        "args = TrainingArguments(\n",
        "    output_dir='ckpt/umberto',\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=10,\n",
        "    lr_scheduler_type='linear',\n",
        "    warmup_steps=500,\n",
        "    logging_steps=50,\n",
        "    eval_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='eval_macro_f1',\n",
        "    report_to=None,\n",
        "    run_name='umberto_full'\n",
        ")\n",
        "\n",
        "trainer = WeightedTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=dtrain,\n",
        "    eval_dataset=dval,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "BSmMyTNpKyW5"
      },
      "id": "BSmMyTNpKyW5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avvio del fine‑tuning\n",
        "trainer.train()\n",
        "print(f\"Migliore eval_macro_f1: {trainer.state.best_metric:.4f}\")"
      ],
      "metadata": {
        "id": "5d7I0JenK339"
      },
      "id": "5d7I0JenK339",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ottimizzazione della soglia per classe e valutazione finale\n",
        "# Predizioni sul validation set\n",
        "eval_preds = trainer.predict(dval)\n",
        "val_logits = eval_preds.predictions\n",
        "val_labels = val_df[LABELS].values.astype(int)\n",
        "\n",
        "# Calcolo probabilità\n",
        "val_probs = sigmoid(torch.tensor(val_logits)).numpy()\n",
        "\n",
        "# Ricerca della soglia ottimale per ogni classe\n",
        "best_thresholds = []\n",
        "for i in range(NUM_LABELS):\n",
        "    best_f1, best_t = 0.0, 0.5\n",
        "    for t in np.linspace(0.1, 0.9, 81):\n",
        "        f1 = f1_score(val_labels[:, i], (val_probs[:, i] >= t).astype(int))\n",
        "        if f1 > best_f1:\n",
        "            best_f1, best_t = f1, t\n",
        "    best_thresholds.append(best_t)\n",
        "print(\"Soglie ottimali per classe:\", dict(zip(LABELS, best_thresholds)))\n",
        "\n",
        "# Valutazione macro‑F1 con soglie ottimizzate\n",
        "preds_opt = (val_probs >= np.array(best_thresholds)).astype(int)\n",
        "final_macro = f1_score(val_labels, preds_opt, average='macro', zero_division=0)\n",
        "print(f\"Macro‑F1 finale ottimizzata: {final_macro:.4f}\")"
      ],
      "metadata": {
        "id": "XetJvl9gK7pb"
      },
      "id": "XetJvl9gK7pb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ⚙️ Colab → GitHub sync (modifiche da emit_setup.ipynb)\n",
        "from google.colab import userdata\n",
        "import os, shutil\n",
        "\n",
        "# 1. Ottieni token GitHub da Secrets o input\n",
        "token = userdata.get('GITHUB_TOKEN')  # richiede input sicuro solo la prima volta\n",
        "repo_url = f\"https://{token}@github.com/Sergio-ddf/emit-llm.git\"\n",
        "\n",
        "# 2. Clona la repo solo se non esiste\n",
        "if not os.path.exists(\"/content/emit-llm\"):\n",
        "    !git clone $repo_url\n",
        "%cd /content/emit-llm\n",
        "\n",
        "# 3. Configura nome utente Git (obbligatorio per commit)\n",
        "!git config user.email \"ddfsergio9@google.com\"\n",
        "!git config user.name  \"Sergio-ddf\"\n",
        "\n",
        "# 4. Copia il notebook attuale dentro la cartella della repo\n",
        "notebook_name = \"emit_setup.ipynb\"\n",
        "src = f\"/content/{notebook_name}\"\n",
        "dst = f\"/content/emit-llm/{notebook_name}\"\n",
        "if os.path.exists(src):\n",
        "    shutil.copyfile(src, dst)\n",
        "    print(f\"✅ Copiato {notebook_name} in repo locale.\")\n",
        "else:\n",
        "    print(\"❌ Notebook non trovato. Salva prima il notebook in Colab.\")\n",
        "\n",
        "# 5. Esegui commit + push\n",
        "!git pull origin main\n",
        "!git add emit_setup.ipynb\n",
        "!git commit -m \"update: modifiche da Colab salvate automaticamente\" || echo \"⏩ Nessuna modifica da committare\"\n",
        "!git push origin main\n"
      ],
      "metadata": {
        "id": "qJ3wSH3fRPtz"
      },
      "id": "qJ3wSH3fRPtz",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}